{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KV Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\markovca\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"kv-rent-data-16-11-2024.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2676 entries, 0 to 2675\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   web_scraper_order      2676 non-null   object \n",
      " 1   web_scraper_start_url  2676 non-null   object \n",
      " 2   listing_link           2676 non-null   object \n",
      " 3   listing_link_href      2676 non-null   object \n",
      " 4   address                2676 non-null   object \n",
      " 5   price                  2676 non-null   object \n",
      " 6   rooms                  2667 non-null   float64\n",
      " 7   area                   2670 non-null   object \n",
      " 8   floor_out_of_floors    2494 non-null   object \n",
      " 9   build_year             2081 non-null   float64\n",
      " 10  condition              2456 non-null   object \n",
      " 11  energy_mark            2311 non-null   object \n",
      " 12  summary                2675 non-null   object \n",
      " 13  description            2633 non-null   object \n",
      " 14  bedrooms               1848 non-null   float64\n",
      " 15  ownership_form         1923 non-null   object \n",
      " 16  katastrinumber         1710 non-null   object \n",
      " 17  description_header     2282 non-null   object \n",
      " 18  description_footer     2676 non-null   object \n",
      " 19  prepayment             637 non-null    object \n",
      " 20  utility_costs          862 non-null    object \n",
      " 21  owner_or_broker        2673 non-null   object \n",
      " 22  registriosa_number     258 non-null    float64\n",
      " 23  images_link            2674 non-null   object \n",
      " 24  images_link_href       2674 non-null   object \n",
      "dtypes: float64(4), object(21)\n",
      "memory usage: 522.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# underscores are easier to work with than hyphens.\n",
    "data.columns = data.columns.str.replace('-', '_')\n",
    "# As we can see, the situation is pretty bad by default.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove the Web Scraper columns.\n",
    "# listing-link and address have the same info, but address has more bloat. \n",
    "# listing-link is easier to filter and split. let's remove address as well\n",
    "# catastre, registry and ownership_form have either no correlation or are mostly NaN values\n",
    "data = data.drop(['web_scraper_order', 'web_scraper_start_url', 'address', 'katastrinumber', 'registriosa_number', 'ownership_form'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## floor_out_of_floors deserves its own chapter - cell formatting is annoying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01-Mar', '03-May', '04-Apr', '01-Feb', '03-Apr', '01-Apr',\n",
       "       '02-Mar', '05-May', '01-May', '04-May', '03-Mar', nan, '02-May',\n",
       "       '06-Jun', '03-Jun', '03-Jul', '04-Feb', '05-Jun', '02-Apr',\n",
       "       '02-Feb', '07-Sep', '04-Jun', '04-Sep', '06-Aug', '09-Sep',\n",
       "       '03-Aug', '04-Jul', '02-Jun', '08-Aug', '05-Jul', '01-Jun',\n",
       "       '01-Aug', '08-Dec', 'Dec-14', '03-Sep', '06-Jul', '01-Jan',\n",
       "       '08-Sep', '04-Aug', '13/30', 'May-14', '01-Sep', 'Apr-14',\n",
       "       '05-Oct', '18/23', '06-Sep', '15/30', '07-Aug', '05-Aug', 'Aug-15',\n",
       "       '05-Sep', '-0.25', '04-Oct', '02-Jan', '02-Jul', '10-Nov',\n",
       "       '02-Sep', 'Jul-16', 'Jun-14', 'Oct-19', 'Jun-13', '09-Dec',\n",
       "       'Feb-14', '10-Dec', '24/30', '15/16', 'Dec-13', '02-Aug', 'May-13',\n",
       "       '07-Nov', '14/20', 'Sep-14', 'Oct-17', '07-Jul', '09-Oct',\n",
       "       '03-Oct', '08-Oct', '03-Feb', '06-Dec', 'Jul-20', 'Nov-19',\n",
       "       'Jul-19', 'Jul-14', '14/14', 'Apr-22', '09-Nov', 'Jun-16',\n",
       "       'Dec-16', 'Apr-13', 'Dec-15', 'Aug-19', '04-Nov', '07-Oct',\n",
       "       '-0.333333333', 'Nov-14', '14/16', '02-Dec', '10-Oct', 'Nov-13',\n",
       "       '05-Dec', 'Mar-16', 'May-16', '17/17', '17/20', '02-Oct', '03-Dec',\n",
       "       'Nov-15', '09-Apr', 'Oct-14', '01-Jul', '15/19', 'Jul-13',\n",
       "       'Aug-16', 'Aug-18', '04-Dec', '03-Nov', '-0.2', 'Mar-14', 'Sep-23',\n",
       "       '11-Dec', '01-Oct', 'Dec-23'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# floor_out_of_floors seems to have had a bit of a mishap. \n",
    "# they were automatically transformed to a date, but they were actually 1/5, 3/5, 1/2 etc.\n",
    "# let's separate all the columns that are easily separable - price, floor_out_of_floors\n",
    "# first, let's check the unique values.\n",
    "data['floor_out_of_floors'].unique()\n",
    "# most of them are pretty clear - Day-Month corresponds to FLOOR-TOTAL_FLOORS\n",
    "# some, however aren't clear: -0.25, -0.333333333, -0.2. These need to be checked individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[data['floor_out_of_floors'] == '-0.25'].iloc[0]['listing-link-href'] # -0.25 is actually a basement floor -1/4\n",
    "#data[data['floor_out_of_floors'] == '-0.25'].iloc[1]['listing-link-href'] # -0.25 is actually a basement floor -1/4\n",
    "# ^ those two listings are actually the same apartment listing two times, \n",
    "# the links really are different, though.\n",
    "#data[data['floor_out_of_floors'] == '-0.333333333'].iloc[0]['listing-link-href'] # -0.333333333 is actually a basement floor -1/3\n",
    "#data[data['floor_out_of_floors'] == '-0.2'].iloc[0]['listing-link-href'] # -0.2 is actually a basement floor -1/5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plan is the following (not the most optimal, but definitely won't break anything):\n",
    "# map -0.25, -0.333333333, -0.2 to -1/4, -1/3, -1/5\n",
    "# map [Jan, Feb, Mar,...] to [1,2,3,...] in each string\n",
    "# somehow this needs to apply to substrings. \n",
    "# map - to / DANGER, map only once FROM RIGHT, otherwise negative floor numbers will be affected\n",
    "# check all unique values\n",
    "# if unique values are all good, then split from / and cast to int\n",
    "## The following is created with help from Claude.ai.\n",
    "def transform_floor_numbers(value):\n",
    "    if pd.isna(value):\n",
    "        return value\n",
    "        \n",
    "    # First handle the special basement cases\n",
    "    basement_map = {\n",
    "        '-0.25': '-1/4',\n",
    "        '-0.333333333': '-1/3',\n",
    "        '-0.2': '-1/5'\n",
    "    }\n",
    "    if str(value) in basement_map:\n",
    "        return basement_map[str(value)]\n",
    "    \n",
    "    # Handle month name conversions\n",
    "    month_map = {\n",
    "        'Jan': '1', 'Feb': '2', 'Mar': '3', 'Apr': '4', \n",
    "        'May': '5', 'Jun': '6', 'Jul': '7', 'Aug': '8', \n",
    "        'Sep': '9', 'Oct': '10', 'Nov': '11', 'Dec': '12'\n",
    "    }\n",
    "    \n",
    "    value = str(value)\n",
    "    # Handle cases like \"Dec-14\"\n",
    "    for month, num in month_map.items():\n",
    "        if month in value:\n",
    "            value = value.replace(month, num)\n",
    "    \n",
    "    # Handle cases where - needs to be converted to / (but only rightmost occurrence)\n",
    "    if '-' in value and '/' not in value:\n",
    "        parts = value.rsplit('-', 1)  # Split from right once\n",
    "        value = parts[0] + '/' + parts[1]\n",
    "        \n",
    "    return value\n",
    "\n",
    "# Apply the transformation\n",
    "data['floor_out_of_floors'] = data['floor_out_of_floors'].apply(transform_floor_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['floor', 'total_floors']] = data['floor_out_of_floors'].str.split('/', expand=True)\n",
    "data['floor'] = pd.to_numeric(data['floor'], errors='coerce')\n",
    "data['total_floors'] = pd.to_numeric(data['total_floors'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elementary column transformations - extracting and cleaning up easy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price -> price, price_per_m2\n",
    "data['price'] = data['price'].apply(lambda x: re.sub(r'\\s', '', x))\n",
    "data[['price', 'price_per_m2']] = data['price'].str.split('€', n=1, expand=True)\n",
    "data['price'] = pd.to_numeric(data['price'].str.strip(), errors='coerce')\n",
    "data['price_per_m2'] = data['price_per_m2'].str.replace('€/m²', '').str.strip()\n",
    "data['price_per_m2'] = pd.to_numeric(data['price_per_m2'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       750.0\n",
       "1       595.0\n",
       "2       670.0\n",
       "3       450.0\n",
       "4       550.0\n",
       "        ...  \n",
       "2671    790.0\n",
       "2672    459.0\n",
       "2673    500.0\n",
       "2674    419.0\n",
       "2675    650.0\n",
       "Name: price, Length: 2676, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area -> float64 area with filtering\n",
    "data['area'] = data['area'].str.replace('\\xa0m²', '').str.strip()\n",
    "data['area'] = pd.to_numeric(data['area'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_mark to numeric, A is highest, H is lowest value\n",
    "data.energy_mark = data.energy_mark.map({\n",
    "    'Puudub': np.nan, '-': np.nan,\n",
    "    'H':1, 'G':2, 'F':3, 'E':4, 'D':5, 'C':6, 'B':7, 'A':8\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary condition mapping to 5 numeric categories\n",
    "data['condition'] = data['condition'].map({\n",
    "    'Uus': 5, 'Uusarendus': 5,\n",
    "    'Renoveeritud': 4,\n",
    "    'Valmis': 3, 'Heas korras': 3,\n",
    "    'San. remont tehtud': 2, 'Keskmine': 2,\n",
    "    'Vajab san. remonti': 1, 'Vajab renoveerimist': 1\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get copy_not_allowed and broker_not_allowed from the footer\n",
    "# used Copilot to simplify this\n",
    "def map_description_footer(df):\n",
    "    df['copy_not_allowed'] = df['description_footer'].apply(lambda x: 'Ei luba enda kuulutust kopeerida' in x)\n",
    "    df['no_broker_allowed'] = df['description_footer'].apply(lambda x: 'Maakleritel palun mitte tülitada' in x)\n",
    "    return df\n",
    "\n",
    "data = map_description_footer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     images_attached\n",
      "50              21.0\n",
      "51               8.0\n",
      "52              36.0\n",
      "53              14.0\n",
      "54              17.0\n",
      "55              24.0\n",
      "56              12.0\n",
      "57              14.0\n",
      "58              19.0\n",
      "59              21.0\n",
      "60              20.0\n",
      "61               9.0\n",
      "62              20.0\n",
      "63              17.0\n",
      "64              35.0\n",
      "65              27.0\n",
      "66              13.0\n",
      "67               7.0\n",
      "68              13.0\n",
      "69              11.0\n",
      "70              29.0\n",
      "71               3.0\n",
      "72              22.0\n",
      "73              16.0\n",
      "74               6.0\n",
      "75              15.0\n",
      "76               8.0\n",
      "77              37.0\n",
      "78               9.0\n",
      "79              20.0\n",
      "80               9.0\n",
      "81              13.0\n",
      "82              19.0\n",
      "83              12.0\n",
      "84              13.0\n",
      "85              20.0\n",
      "86              30.0\n",
      "87              45.0\n",
      "88              12.0\n",
      "89              21.0\n",
      "90              10.0\n",
      "91               8.0\n",
      "92              16.0\n",
      "93              11.0\n",
      "94              17.0\n",
      "95              14.0\n",
      "96              13.0\n",
      "97              20.0\n",
      "98              18.0\n",
      "99              12.0\n",
      "100             11.0\n"
     ]
    }
   ],
   "source": [
    "# from images_link, we can get the number of pictures attached to the post. that seems like a worthwhile data point to have\n",
    "# we can use a regex function for that. used Copilot to check the correct regex function in python\n",
    "def extract_images_attached(df):\n",
    "    df['images_attached'] = df['images_link'].str.extract(r'\\((\\d+)\\)')\n",
    "    df['images_attached'] = pd.to_numeric(df['images_attached'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "data = extract_images_attached(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['listing_link', 'listing_link_href', 'price', 'rooms', 'area',\n",
       "       'floor_out_of_floors', 'build_year', 'condition', 'energy_mark',\n",
       "       'summary', 'description', 'bedrooms', 'description_header',\n",
       "       'description_footer', 'prepayment', 'utility_costs', 'owner_or_broker',\n",
       "       'images_link', 'images_link_href', 'floor', 'total_floors',\n",
       "       'price_per_m2', 'copy_not_allowed', 'no_broker_allowed',\n",
       "       'images_attached'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract whether poster is the owner depending on the owner-broker banner\n",
    "data['is_owner'] = data['owner_or_broker'].str.contains('Omanik')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert prepayment to numeric\n",
    "data['prepayment'] = pd.to_numeric(data['prepayment'].str.replace('€', '').str.strip(), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have all the column dropping in the last cell.\n",
    "data = data.drop(['images_link', 'description_footer', 'floor_out_of_floors', 'owner_or_broker'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing some extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two rows have 29 rooms listed.\n",
    "# those are actually \"shared housing\" listing & no rooms cost 200 - the cheapest is 350. Let's drop those rows.\n",
    "data = data.drop(data[data.rooms == 29].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[data.rooms.isna()] # 9 rows, let's leave those in for \"comparison with no room nr\"\n",
    "#data[data.rooms == 8] # 2 rows, seem correct\n",
    "#data[data.rooms == 6] # 5 rows\n",
    "#data[data.rooms == 5] # 22 rows, that's good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row with index 2145 has price 1€ and area as 1 m2. Not going to bother finding out what's happening.\n",
    "data = data.drop(2145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since price is the feature we're trying to predict and area is a good indication of price,\n",
    "# let's drop all rows where price or area is NaN\n",
    "#data = data.drop(data[data.rooms == 29].index)\n",
    "data = data.drop(data[(data['price'].isna()) | (data['area'].isna())].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of the objects has a build year above 20000, that's actually supposed to be 2022\n",
    "data.loc[1877, 'build_year'] = 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 rows have a price above 15000. those are either sale listings or bad typos, not worth figuring out.\n",
    "data = data.drop(data[data.price > 15000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 post is a \"combo posting\" of 5 apartments where area is only 1 apt, but price is 5 apt. Not going to figure all the details out\n",
    "data = data.drop(data[data.price_per_m2 > 60].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually verified that the 3 is_owner banners that are NaN are truly posted by the owner 2449 2479 2572\n",
    "# replace is_owner NaN with True\n",
    "# data[data.is_owner.isna() == True]\n",
    "data.loc[[2449, 2479, 2572], 'is_owner'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.is_owner = data.is_owner.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one listing is actually for a storage room\n",
    "data = data.drop(data[data.area == 3].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract summer and winter utility costs from utility_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['30 € / -', '86 € / 162 €', '70 € / 200 €', '75 € / 140 €',\n",
       "       '45 € / 85 €', '81 € / 138 €', '88 € / -', '220 € / 250 €',\n",
       "       '80 € / 280 €'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.utility_costs.unique()[390:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace € with '', strip()\n",
    "data['utility_costs'] = data['utility_costs'].str.replace('€', '')\n",
    "# split from /\n",
    "data[['utility_summer', 'utility_winter']] = data['utility_costs'].str.split('/', n=1, expand=True)\n",
    "# to_numeric\n",
    "data['utility_summer'] = pd.to_numeric(data['utility_summer'], errors='coerce')\n",
    "data['utility_winter'] = pd.to_numeric(data['utility_winter'], errors='coerce')\n",
    "# drop utility_costs\n",
    "data = data.drop(['utility_costs'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if one exists and other doesn't, copy value from one to the other.\n",
    "# this is not a perfect solution, but still gives us about 30 extra rows to work with.\n",
    "data.loc[(data['utility_summer'].isna()) & (data['utility_winter'].notna()), 'utility_summer'] = data['utility_winter']\n",
    "data.loc[(data['utility_winter'].isna()) & (data['utility_summer'].notna()), 'utility_winter'] = data['utility_summer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 posts are badly formatted and very difficult to parse\n",
    "data = data.drop([510, 1693])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 post (2133) had an utility bill of over 100 000€ summer/winter. let's replace that with NaN\n",
    "# 2 posts have utility bills equal to the rent, while saying that utility bills are fixed\n",
    "data.loc[2133, 'utility_summer'] = np.nan\n",
    "data.loc[2133, 'utility_winter'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2655 entries, 0 to 2675\n",
      "Data columns (total 23 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   listing_link        2655 non-null   object \n",
      " 1   listing_link_href   2655 non-null   object \n",
      " 2   price               2655 non-null   float64\n",
      " 3   rooms               2646 non-null   float64\n",
      " 4   area                2655 non-null   float64\n",
      " 5   build_year          2066 non-null   float64\n",
      " 6   condition           2435 non-null   float64\n",
      " 7   energy_mark         1207 non-null   float64\n",
      " 8   summary             2654 non-null   object \n",
      " 9   description         2612 non-null   object \n",
      " 10  bedrooms            1836 non-null   float64\n",
      " 11  description_header  2266 non-null   object \n",
      " 12  prepayment          560 non-null    float64\n",
      " 13  images_link_href    2653 non-null   object \n",
      " 14  floor               2475 non-null   float64\n",
      " 15  total_floors        2475 non-null   float64\n",
      " 16  price_per_m2        2655 non-null   float64\n",
      " 17  copy_not_allowed    2655 non-null   bool   \n",
      " 18  no_broker_allowed   2655 non-null   bool   \n",
      " 19  images_attached     2653 non-null   float64\n",
      " 20  is_owner            2655 non-null   bool   \n",
      " 21  utility_summer      855 non-null    float64\n",
      " 22  utility_winter      855 non-null    float64\n",
      "dtypes: bool(3), float64(14), object(6)\n",
      "memory usage: 507.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting address fields from listing_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, 6, 7], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['listing_link'].str.split(',').apply(lambda x: len(x)).unique() # address separated by ',' returns len 4, 5, 3, 6, 8, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2            Tartumaa, Tartu, Tartu linn, Kesklinn, Oru 2\n",
       "3       Pärnumaa, Pärnu, Pärnu linn, Rannarajoon, Papl...\n",
       "8           Tartumaa, Tartu, Tartu linn, Karlova, Turu 29\n",
       "10       Harjumaa, Tallinn, Kristiine, Kristiine, Kotka 1\n",
       "13         Tartumaa, Tartu, Tartu linn, Kesklinn, Riia 26\n",
       "                              ...                        \n",
       "2665    Tartumaa, Tartu, Tartu linn, Kesklinn, Väike-T...\n",
       "2668    Tartumaa, Tartu, Tartu linn, Kesklinn, Vanemui...\n",
       "2670    Tartumaa, Tartu, Tartu linn, Tammelinn, Soinas...\n",
       "2673    Harjumaa, Tallinn, Kesklinn, Juhkentali, Liiva...\n",
       "2675    Harjumaa, Rae vald, Rae, Rae küla, Dolomiidi t...\n",
       "Name: listing_link, Length: 880, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['listing_link'].str.split(',').apply(lambda x: len(x) == 5)].listing_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNTY, MUNICIPALITY?, CITY, (DISTRICT)*, STREET_ADDRESS\n",
    "# I think we will try to go with the first two fields for county and municipality or city, then take the last field for a street address\n",
    "def extract_address_components(address):\n",
    "    parts = address.split(',')\n",
    "    county = parts[0].strip()\n",
    "    # replacing \"vald\" (abbr. for municipality) reduces complexity and unique variables while resulting a small data loss that the street address often solves\n",
    "    mun_or_city = parts[1].replace(' vald', '').strip()\n",
    "    # replacing \"tn\" (abbreviation for street) makes it more suitable for different APIs, for example, OpenStreetMap, if we decide to use that\n",
    "    street_adr = parts[-1].replace(' tn', '').strip()\n",
    "    return county, mun_or_city, street_adr\n",
    "\n",
    "data[['county', 'mun_or_city', 'street_adr']] = data['listing_link'].apply(lambda x: pd.Series(extract_address_components(x)))\n",
    "data = data.drop(['listing_link'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Voorimehe 1', 'Kivi 25', 'Oru 2', 'Papli 20', 'Pikaliiva 5',\n",
       "       'Väike-Patarei 1/3', 'Pebre 3', 'Õismäe tee 175', 'Turu 29',\n",
       "       'Mahla 67', 'Kotka 1', 'Aasa 5', 'Mere pst 4', 'Riia 26',\n",
       "       'Keskuse 12', 'Pärnu mnt 32', 'Ravila 48', 'Kesk 11', 'Koidula 26',\n",
       "       'Suur-Lossi 16', 'Tõnismägi 11a', 'Pikk 40', 'Pikk 33',\n",
       "       'Koidu 62--', 'Hane 4-7', 'Valli 4', 'Meierei 30', 'Randla 13',\n",
       "       'Raua 34', 'Asunduse 9', 'Ahtme mnt 57', 'Kuklase 3', 'Raadiku 14',\n",
       "       'Pilve 4-16', 'Aiandi 5/3', 'J. Sütiste tee 39', 'Ümera',\n",
       "       'Sõmera 4a', 'Mäealuse 9', 'Riia 9', 'Tamme 24', 'Dunkri 2',\n",
       "       'Vanemuise', 'Pallasti 33', 'Talli 2', 'Pargi 1', 'Rüütli 22',\n",
       "       'A. Puškini 51', 'Puiestee', 'Kangelaste prospekt 10a',\n",
       "       'F. R. Faehlmanni 8', 'F. R. Faehlmanni 6', 'Kalda tee 14',\n",
       "       'Kungla 18', 'J. V. Jannseni 4', 'Pille 7/4', 'Uus 13c',\n",
       "       'Hariduse 12', 'Tildri 7', 'Pikk 5', 'Partisani 9', 'Pärnu mnt 33',\n",
       "       'Lutsu 14', 'Kooli 6a', 'Vallikraavi 10', 'Merivälja tee 70',\n",
       "       'Pilve 4-13', 'Kopli tee 28', 'Puiestee 112a', 'Vana Kalamaja 10',\n",
       "       'Põhja allee 11-31', 'Varbola keskus 77', 'Volta 34',\n",
       "       'J. Sütiste tee 26', 'Aiandi 11/1-29b', 'Tiigi 6', 'Sõjakooli 14',\n",
       "       'Uus-Kalamaja 7/1', 'Väike-Kaar 43', 'KALDA tee', 'Kesk 22',\n",
       "       'Laine 8', 'Saturni 14', 'Erika 7', 'Lai 35', 'Allveelaeva 4',\n",
       "       'Liivamäe 6', 'J. Kuperjanovi 8', 'Vabriku 13', 'Karja 3',\n",
       "       'Puhangu 8', 'Pikk 22-4', 'Aasa 12', 'Laki 24', 'Kanali 8F',\n",
       "       'Pepleri 23', 'Kreutzwaldi 13', 'Järve 33', 'Kivi 9', 'Küüni 4'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.street_adr.unique()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting info from summary                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     house_type\n",
      "50     Kivimaja\n",
      "52     Kivimaja\n",
      "53   Paneelmaja\n",
      "54     Puitmaja\n",
      "55     Kivimaja\n",
      "56     Kivimaja\n",
      "57          NaN\n",
      "58          NaN\n",
      "59     Kivimaja\n",
      "60          NaN\n",
      "61          NaN\n",
      "62     Kivimaja\n",
      "63     Kivimaja\n",
      "64         Maja\n",
      "65     Kivimaja\n",
      "66     Kivimaja\n",
      "67     Kivimaja\n",
      "68     Kivimaja\n",
      "69   Paneelmaja\n",
      "70   Paneelmaja\n",
      "71          NaN\n",
      "72   Paneelmaja\n",
      "73     Puitmaja\n",
      "74          NaN\n",
      "75          NaN\n",
      "76     Kivimaja\n",
      "77          NaN\n",
      "78     Puitmaja\n",
      "80     Kivimaja\n",
      "81          NaN\n",
      "82     Kivimaja\n",
      "83     Kivimaja\n",
      "84     Puitmaja\n",
      "85     Kivimaja\n",
      "86          NaN\n",
      "87          NaN\n",
      "88          NaN\n",
      "89     Kivimaja\n",
      "90          NaN\n",
      "91     Kivimaja\n",
      "92     Kivimaja\n",
      "93   Paneelmaja\n",
      "94     Kivimaja\n",
      "95     Kivimaja\n",
      "96   Paneelmaja\n",
      "97          NaN\n",
      "98     Kivimaja\n",
      "99     Kivimaja\n",
      "100         NaN\n",
      "101    Kivimaja\n",
      "102    Kivimaja\n"
     ]
    }
   ],
   "source": [
    "#maja tüübid\n",
    "data['house_type'] = data['summary'].str.extract(r'(?i)(Kivimaja|Paneelmaja|Puitmaja|Maja)', expand=False)\n",
    "\n",
    "# View rows again\n",
    "data['house_type'] = data['house_type'].str.capitalize()\n",
    "print(data[['house_type']].iloc[50:101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Korteriomand\n",
      "\n",
      "Köök: keraamiline pliit, avatud köök, külmik \n",
      "Sanruum: dušš, pesumasin \n",
      "Lisainfo: köök, mööbel, tsentraalne vesi, ühistransport, parkett, garderoob, seinakapp \n",
      "Side ja turvalisus: trepikoda lukus\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "print(data['summary'].iloc[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                     elektriküte\n",
      "1                                        keskküte\n",
      "2                                 keskküte, kamin\n",
      "3    Õhk-vesisoojuspump, põrandaküte, elektriküte\n",
      "4                                             NaN\n",
      "5                                        keskküte\n",
      "6                         õhksoojuspump, ahjuküte\n",
      "7                                        keskküte\n",
      "8                                        keskküte\n",
      "9                                             NaN\n",
      "Name: heating, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#which types of heating are there\n",
    "#is it okay that some have more than 1??\n",
    "data['heating'] = data['summary'].str.extract(r'Küte ja ventilatsioon:\\s*(.*?)(?:\\r\\n|\\r|\\n|$)', expand=False).str.strip()\n",
    "\n",
    "print(data['heating'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      True\n",
      "1      True\n",
      "2      True\n",
      "3      True\n",
      "4      True\n",
      "5      True\n",
      "6      True\n",
      "7      True\n",
      "8     False\n",
      "9      True\n",
      "10     True\n",
      "11    False\n",
      "12     True\n",
      "13     True\n",
      "14     True\n",
      "15     True\n",
      "16     True\n",
      "17    False\n",
      "18     True\n",
      "Name: furnished, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#kas mööbel tuleb kaasa korteriga või ei? BOOLEAN\n",
    "data['furnished'] = data['summary'].str.contains(r'\\bmööbel\\b|\\bmööbli võimalus\\b', case=False, regex=True)\n",
    "\n",
    "# Check the results\n",
    "print(data['furnished'].head(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      True\n",
      "1      True\n",
      "2      True\n",
      "3      True\n",
      "4     False\n",
      "5      True\n",
      "6      True\n",
      "7      True\n",
      "8     False\n",
      "9      True\n",
      "10     True\n",
      "11    False\n",
      "12     True\n",
      "13     True\n",
      "14     True\n",
      "15     True\n",
      "16     True\n",
      "17    False\n",
      "18     True\n",
      "Name: washing_machine, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#kas pesumasin on ka korteris?\n",
    "data['washing_machine'] = data['summary'].str.contains(r'\\bpesumasin\\b', case=False, regex=True)\n",
    "print(data['washing_machine'].head(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1      True\n",
      "2      True\n",
      "3     False\n",
      "4     False\n",
      "5      True\n",
      "6     False\n",
      "7      True\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11     True\n",
      "12     True\n",
      "13    False\n",
      "14     True\n",
      "15    False\n",
      "16    False\n",
      "17     True\n",
      "18    False\n",
      "Name: balcony, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#kas on rõdu?\n",
    "data['balcony'] = data['summary'].str.contains(r'\\brõdu\\b', case=False, regex=True)\n",
    "print(data['balcony'].head(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1     False\n",
      "2      True\n",
      "3      True\n",
      "4     False\n",
      "5     False\n",
      "6      True\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "18     True\n",
      "Name: yard, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "#kas on hoopis hoov??? boolean väärtus\n",
    "data['yard'] = data['summary'].str.contains(r'\\bhoov\\b', case=False, regex=True)\n",
    "print(data['yard'].head(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3      True\n",
      "4     False\n",
      "5      True\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "18    False\n",
      "Name: terrace, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "#kas on hoopis terass??? boolean väärtus\n",
    "data['terrace'] = data['summary'].str.contains(r'\\bterrass\\b', case=False, regex=True)\n",
    "print(data['terrace'].head(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1      True\n",
      "2      True\n",
      "3      True\n",
      "4      True\n",
      "5     False\n",
      "6      True\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10     True\n",
      "11     True\n",
      "12     True\n",
      "13     True\n",
      "14     True\n",
      "15    False\n",
      "16    False\n",
      "17     True\n",
      "18     True\n",
      "Name: parking, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#kas parkida saab tasuta?\n",
    "data['parking'] = data['summary'].str.contains(r'\\bparkimine tasuta\\b', case=False, regex=True)\n",
    "print(data['parking'].head(19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  has_internet has_security_door has_video_surveillance\n",
      "0         True              True                  False\n",
      "1         True              True                  False\n",
      "2         True              True                  False\n",
      "3         True             False                  False\n",
      "4        False             False                  False\n",
      "5        False             False                  False\n",
      "6         True              True                  False\n",
      "7         True              True                   True\n",
      "8        False             False                  False\n",
      "9        False             False                  False\n"
     ]
    }
   ],
   "source": [
    "#kas on internet, turvauks, videovalve? boolean väärtused kõik\n",
    "data['has_internet'] = data['summary'].str.contains(r'\\bInternet\\b', case=False, regex=True)\n",
    "data['has_security_door'] = data['summary'].str.contains(r'\\bTurvauks\\b', case=False, regex=True)\n",
    "data['has_video_surveillance'] = data['summary'].str.contains(r'\\bVideovalve\\b', case=False, regex=True)\n",
    "\n",
    "print(data[['has_internet', 'has_security_door', 'has_video_surveillance']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       False\n",
      "1       False\n",
      "2        True\n",
      "3       False\n",
      "4        True\n",
      "        ...  \n",
      "2671     True\n",
      "2672     True\n",
      "2673    False\n",
      "2674     True\n",
      "2675     True\n",
      "Name: has_storage, Length: 2655, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#kas summarys on toodud kas seal on ka panipaik? boolean väärtus\n",
    "\n",
    "data['has_storage'] = data['summary'].str.contains(r'\\bPanipaik\\b', case=False, regex=True)\n",
    "print(data['has_storage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Korteriomand, kivimaja\\r\\n\\r\\nKöök: gaasipliit, avatud köök, külmik, köögimööbel \\r\\nSanruum: dušš, uus torustik, vann, pesumasin \\r\\nKüte ja ventilatsioon: keskküte, kamin \\r\\nLisainfo: rõdu 18\\xa0m², parkett, pakettaknad, mööbel, TV, katusekorter, kinnine hoov, uus elektrijuhtmestik, seinakapp, panipaik, parkimine tasuta \\r\\nSide ja turvalisus: Internet, telefon, kaabelTV, valvesüsteem paigaldatud, turvauks, trepikoda lukus, naabrivalve \\r\\nÜmbrus: ümbruses eramud ja korterelamud, teed heas seisukorras, asub keskuses'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['summary'].iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting info from description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KORTER\\r\\nAnname üürile renoveeritud ja möbleeritud korteri Paldiski linnas.\\r\\nKorteri koosseisu kuulub avar elutuba koos köögiga, osaliselt eraldatud magamistuba, esik ning WC koos duširuumiga. \\r\\n\\r\\nTegemist on väga sooja, hubase ja valgusküllase koduga. \\r\\nPakutav korter asub esimesel korrusel, seega sobib hästi ka väikse lapsega perekonnale või vanemale inimesele.\\r\\n\\r\\nMAJA/PARKIMINE\\r\\nRae 36 kortermaja on täielikult renoveeritud 15 aastat tagasi. Kõik tehnosüsteemid on uued. Maja ümbrus ja trepikoda näeb kena välja ja on kogu aeg hooldatud.\\r\\nParkimine maja taga kinnises hoovis, kindel parkimiskoht. Hooviala avaneb telefoniga helistades.\\r\\nLisaks on olemas turvaline panipaik hoone 0-korrusel. \\r\\n\\r\\nÜürilepingu sõlmimisel tuleb tasuda:\\r\\n- Esimese kuu üüri ettemaks 350€\\r\\n- Tagatisraha 350€\\r\\n- Lepingutasu 350€'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description'].iloc[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['listing_link_href', 'price', 'rooms', 'area', 'build_year',\n",
       "       'condition', 'energy_mark', 'summary', 'description', 'bedrooms',\n",
       "       'description_header', 'prepayment', 'images_link_href', 'floor',\n",
       "       'total_floors', 'price_per_m2', 'copy_not_allowed', 'no_broker_allowed',\n",
       "       'images_attached', 'is_owner', 'utility_summer', 'utility_winter',\n",
       "       'county', 'mun_or_city', 'street_adr', 'house_type', 'heating',\n",
       "       'furnished', 'washing_machine', 'balcony', 'yard', 'terrace', 'parking',\n",
       "       'has_internet', 'has_security_door', 'has_video_surveillance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     False\n",
      "1      True\n",
      "2     False\n",
      "3      True\n",
      "4     False\n",
      "5     False\n",
      "6     False\n",
      "7     False\n",
      "8     False\n",
      "9     False\n",
      "10    False\n",
      "11    False\n",
      "12    False\n",
      "13    False\n",
      "14    False\n",
      "15    False\n",
      "16    False\n",
      "17    False\n",
      "18    False\n",
      "19     True\n",
      "Name: has_advance_payment, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markovca\\AppData\\Local\\Temp\\ipykernel_22888\\2423924742.py:1: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  data['has_advance_payment'] = data['description'].str.contains(\n"
     ]
    }
   ],
   "source": [
    "data['has_advance_payment'] = data['description'].str.contains(\n",
    "    r'1 kuu (ettemaks|üür)',  # Match phrases like \"1 kuu ettemaks\" or \"1 kuu üür\"\n",
    "    case=False, \n",
    "    regex=True\n",
    ")\n",
    "\n",
    "print(data['has_advance_payment'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ÜÜRILE ANDA HEA ASUKOHAGA VÄGA ILUS KAHETOALINE KORTER!\\r\\n \\r\\n Rendile anda stiilne ja kena kahetoaline korter Põhja-Tallinnas!\\r\\n Korter on vaba vaatamiseks ja üleandmiseks alates 14. november.\\r\\n Kõik eluks vajalik on koheselt olemas!\\r\\n Täismöbleeritud!\\r\\n \\r\\n Põrandaid katab puitparkett.\\r\\n Rendile anda koos kogu sisustusega.\\r\\n Magamistoas on suur walk-in garderoob ja paigaldatud on kaasaaegne köögimööbel koos tehnikaga.\\r\\n Ruumilahendus on hästi läbi mõeldud.\\r\\n Korteril on mõnus terrass!\\r\\n \\r\\n Küttesüsteemid ja kommunikatsioonid:\\r\\n Korteris on keskküte.\\r\\n Kõikjal on vesipõrandaküte.\\r\\n Soojustagastusega ventilatsioonisüsteem.\\r\\n \\r\\n Minimaalne üürimisperiood on 12 kuud.\\r\\n \\r\\n Lepingu sõlmimisel küsitakse esimene üür, tagatisraha ühe kuu üüri ulatuses ning lepingutasu ühe kuu üürisumma + käibemaks.\\r\\n \\r\\n Igakuisele üürisummale 800 eurot lisanduvad igakuised kommunaalkulud! \\r\\n \\r\\n Helista ja küsi lisa!'"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description'].iloc[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UUS HIND!\\r\\n Üürile anda koheselt kahetoaline terrassiga korter Pärnu rannarajoonis!\\r\\n Korter on kevadel remonditud.\\r\\n \\r\\n Korter asub elamu 1. korrusel ning koosneb avatud köögiosast, elutoast, magamistoast, wc-duširuumist, esikuosast ja lisaks suurest terrassist hommikupäikese poole.\\r\\n Olemas vajalik sisustus, kodumasinad- nõudepesumasin, pesumasin, külmkapp koos sügavkülmaga, veekeetja, televiisor, õhksoojuspump, mikrolaineahi.\\r\\n \\r\\n Auto saab mugavalt tasuta parkida elamu ette üks autokoht.\\r\\n Küte korteris: elekter + õhksoojuspump.\\r\\n \\r\\n Üüritakse välja koheselt ja pikemaks perioodiks. \\r\\n Üürisumma on 450 eurot kuus, millele lisanduvad kommunaalmaksud.\\r\\n \\r\\n Tasumine: \\r\\n 1 kuu ettemaks 450 eurot\\r\\n tagatisraha 450 eurot\\r\\n maakleritasu 400 eurot\\r\\n \\r\\n Helista ja kirjuta lisainfo saamiseks!\\r\\n Kohtumiseni!'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract info from description header - is it in all caps (bool)? Count !? and something like that maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        True\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "2671     True\n",
      "2672    False\n",
      "2673     True\n",
      "2674    False\n",
      "2675    False\n",
      "Name: description_header_is_all_caps, Length: 2655, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "#is the header all in caps or not\n",
    "data['description_header_is_all_caps'] = data['description_header'].str.isupper()\n",
    "data['description_header_is_all_caps'] = data['is_all_caps'].fillna(False)\n",
    "\n",
    "print(data['description_header_is_all_caps'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       30.0\n",
      "1       40.0\n",
      "2        0.0\n",
      "3       50.0\n",
      "4       47.0\n",
      "        ... \n",
      "2671    41.0\n",
      "2672    50.0\n",
      "2673    38.0\n",
      "2674    50.0\n",
      "2675    38.0\n",
      "Name: description_header_length, Length: 2655, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#äkki ka pikkus näitab midagi, et kui pikk või lühike header on loendades charactere: \n",
    "data['description_header_length'] = data['description_header'].str.len()\n",
    "data['description_header_length'] = data['header_length'].fillna(0)\n",
    "\n",
    "print(data['description_header_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                          STUUDIOKORTER RAEKOJA PLATSIL!\n",
      "1                Möbleeritud rõduga korter, parkimiskoht.\n",
      "2                                                     NaN\n",
      "3       Pikaajalise üürile terrassiga korter rannarajo...\n",
      "4         Super Pakkumine! Parkimiskoht, panipaik hinnas!\n",
      "                              ...                        \n",
      "2671            UUS HIND! TULE KLIENDIPÄEVALE 19.11.2024!\n",
      "2672    Lepingutasu al 149€ |Tasuta WiFi|Depovaba võim...\n",
      "2673               UUS REMONT, UUS MÖÖBEL! OLE 1. ELANIK!\n",
      "2674    Lepingutasu al 149€ |Tasuta WiFi|Depovaba võim...\n",
      "2675               A-energiaklassi kodu! Sisustus hinnas!\n",
      "Name: description_header, Length: 2655, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['description_header'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine whether to try to analyse pictures from images_link_href and assign a rating to those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove links (listing_link_href, images_link_href) before fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
